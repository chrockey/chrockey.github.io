---
---

@string{cvpr = {{IEEE/CVF} Conference on Computer Vision and Pattern Recognition (CVPR),}}
@string{eccv = {European Conference on Computer Vision (ECCV),}}

@inproceedings{kim2022selca,
  title={SeLCA: Self-Supervised Learning of Canonical Axis},
  author={Seungwook Kim* and Yoonwoo Jeong* and Chunghyun Park* and Jaesik Park and Minsu Cho},
  abstract={Robustness to rotation is critical for point cloud understanding tasks, as point cloud features can be affected dramatically with respect to prevalent rotation changes. In this work, we propose SeLCA, a novel self-supervised learning framework to learn to the canonical axis of point clouds in a probabilistic manner. In essence, we propose to learn rotationalequivariance by predicting the canonical axis of point clouds, and achieve rotationalinvariance by aligning the point clouds using their predicted canonical axis. When integrated into a rotation-sensitive pipeline, SeLCA achieves competitive performances on the ModelNet40 classification task under unseen rotations. Most interestingly, our proposed method also shows high robustness to various real-world point cloud corruptions presented by the ModelNet40-C dataset, compared to the state-of-the-art rotation-invariant method.},
  booktitle={Conference on Neural Information Processing Systems Workshop - Symmetry and Geometry in Neural Representations (NeurReps),},
  year={2022},
  abbr={NeurIPSW},
  selected={true},
  pdf={kim2022selca.pdf},
  img_path={assets/img/kim2022selca.jpeg},
  equal_contrib={true}
}

@inproceedings{choe2022pointmixer,
  title={PointMixer: MLP-Mixer for Point Cloud Understanding},
  author={Jaesung Choe* and Chunghyun Park* and Francois Rameau and Jaesik Park and In So Kweon},
  abstract={MLP-Mixer has newly appeared as a new challenger against the realm of CNNs and Transformer. Despite its simplicity compared to Transformer, the concept of channel-mixing MLPs and token-mixing MLPs achieves noticeable performance in image recognition tasks. Unlike images, point clouds are inherently sparse, unordered and irregular, which limits the direct use of MLP-Mixer for point cloud understanding. To overcome these limitations, we propose PointMixer, a universal point set operator that facilitates information sharing among unstructured 3D point cloud. By simply replacing token-mixing MLPs with Softmax function, PointMixer can ``mix" features within/between point sets. By doing so, PointMixer can be broadly used for intra-set, inter-set, and hierarchical-set mixing. We demonstrate that various channel-wise feature aggregation in numerous point sets is better than self-attention layers or dense token-wise interaction in a view of parameter efficiency and accuracy. Extensive experiments show the competitive or superior performance of PointMixer in semantic segmentation, classification, and reconstruction against Transformer-based methods.},
  booktitle=eccv,
  year={2022},
  abbr={ECCV},
  arxiv={2111.11187},
  selected={true},
  code={https://github.com/LifeBeyondExpectations/ECCV22-PointMixer},
  img_path={assets/img/choe2022pointmixer.jpeg},
  equal_contrib={true},
  additional_info={Qualcomm Innovation Fellowship 2022 Finalist}
}

@inproceedings{park2022fast,
 title={{Fast Point Transformer}},
 author={Chunghyun Park and Yoonwoo Jeong and Minsu Cho and Jaesik Park},
 abstract={The recent success of neural networks enables a better interpretation of 3D point clouds, but processing a large-scale 3D scene remains a challenging problem. Most current approaches divide a large-scale scene into small regions and combine the local predictions together. However, this scheme inevitably involves additional stages for pre- and post-processing and may also degrade the final output due to predictions in a local perspective. This paper introduces Fast Point Transformer that consists of a new lightweight self-attention layer. Our approach encodes continuous 3D coordinates, and the voxel hashing-based architecture boosts computational efficiency. The proposed method is demonstrated with 3D semantic segmentation and 3D detection. The accuracy of our approach is competitive to the best voxel-based method, and our network achieves 129 times faster inference time than the state-of-the-art, Point Transformer, with a reasonable accuracy trade-off in 3D semantic segmentation on S3DIS dataset.},
 booktitle=cvpr,
 year={2022},
 abbr={CVPR},
 arxiv={2112.04702},
 selected={true},
 code={https://github.com/POSTECH-CVLab/FastPointTransformer},
 website={http://cvlab.postech.ac.kr/research/FPT/},
 img_path={assets/img/park2022fast.png},
 additional_info={Silver Prize @ the 28th HumanTech Paper Award},
 additional_info2={Qualcomm Innovation Fellowship 2022 Winner}
}

@article{DEN.47.777,
  abbr={DEN},
  title={Improved Classification and Localization Approach to Small Bowel Capsule Endoscopy using Convolutional Neural Network},
  author={Yunseob Hwang* and Han Hee Lee* and Chunghyun Park and Bayu Adhi Tama and Jin Su Kim and Dae Young Cheung and Woo Chul Chung and Young-Seok Cho and Kang-Moon Lee and Myung-Gyu Choi and Seungchul Lee},
  abstract={Although great advances in artificial intelligence for interpreting small bowel capsule endoscopy (SBCE) images have been made in recent years, its practical use is still limited. The aim of this study was to develop a more practical convolutional neural network (CNN) algorithm for the automatic detection of various small bowel lesions.},
  journal={Digestive Endoscopy,},
  volume={33},
  issue={4},
  pages={598--607},
  numpages={0},
  year={2021},
  publisher={Japan Gastroenterological Endoscopy Society,},
  doi={10.1111/den.13787},
  html={https://onlinelibrary.wiley.com/doi/10.1111/den.13787},
  pdf={den.pdf},
  selected={false},
  img_path={assets/img/den-47-777.png},
  equal_contrib={true}
}
